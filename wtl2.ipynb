{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68f4d430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import cv2\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import scipy.io as sio\n",
    "import scipy.ndimage as ndi\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import convolve2d, convolve\n",
    "from skimage.morphology import skeletonize, remove_small_objects\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.color import label2rgb\n",
    "from IPython import display\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53376d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TracerNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(4, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(576, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.regressor(x)\n",
    "        x = F.normalize(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "405446ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ported from https://github.com/tsogkas/matlab-utils/blob/master/nms.m\n",
    "def contour_orient(E, r):\n",
    "    if r <= 1:\n",
    "        p = 12 / r / (r + 2) - 2\n",
    "        f = np.array([1, p, 1]) / (2 + p)\n",
    "        r = 1\n",
    "    else:\n",
    "        f = np.concatenate([np.arange(1, r+1), [r+1], np.arange(r, 0, -1)]) / (r + 1)**2\n",
    "    E2 = np.pad(E, [r, r], mode='symmetric')\n",
    "    E2 = convolve(convolve(E2, f[np.newaxis], mode='valid'), f[:, np.newaxis], mode='valid')\n",
    "    grad_f = np.array([-1, 2, -1])\n",
    "    Dx = convolve2d(E2, grad_f[np.newaxis], mode='same')\n",
    "    Dy = convolve2d(E2, grad_f[:, np.newaxis], mode='same')\n",
    "    f = np.array([[1, 0, -1], [0, 0, 0], [-1, 0, 1]])\n",
    "    F = convolve2d(E2, f, mode='same') > 0\n",
    "    Dy[F] = -Dy[F]\n",
    "    return np.mod(np.arctan2(Dy, Dx), np.pi)\n",
    "\n",
    "def nms(E, r=3, s=1):\n",
    "    E = E.copy()\n",
    "    O = contour_orient(E, r)\n",
    "    \n",
    "    Dx = np.cos(O)\n",
    "    Dy = np.sin(O)\n",
    "    \n",
    "    ht, wd = E.shape\n",
    "    E1 = np.pad(E, r+1, mode='edge')\n",
    "    \n",
    "    cs, rs = np.meshgrid(np.arange(wd), np.arange(ht))\n",
    "\n",
    "    for i in range(-r, r+1):\n",
    "        if i == 0: continue\n",
    "        cs0 = i * Dx + cs\n",
    "        dcs = cs0 - np.floor(cs0)\n",
    "        cs0 = np.floor(cs0).astype(int)\n",
    "        \n",
    "        rs0 = i * Dy + rs\n",
    "        drs = rs0 - np.floor(rs0)\n",
    "        rs0 = np.floor(rs0).astype(int)\n",
    "        \n",
    "        rs0_p = rs0 + r + 1\n",
    "        cs0_p = cs0 + r + 1\n",
    "\n",
    "        rs0_p = np.clip(rs0_p, 0, ht + 2*r)\n",
    "        cs0_p = np.clip(cs0_p, 0, wd + 2*r)\n",
    "        \n",
    "        E2 = (1 - dcs) * (1 - drs) * E1[rs0_p + 0, cs0_p + 0]\n",
    "        E2 += dcs * (1 - drs) * E1[rs0_p + 0, cs0_p + 1]\n",
    "        E2 += (1 - dcs) * drs * E1[rs0_p + 1, cs0_p + 0]\n",
    "        E2 += dcs * drs * E1[rs0_p + 1, cs0_p + 1]\n",
    "\n",
    "        E[E * 1.01 < E2] = 0\n",
    "\n",
    "    for i in range(s):\n",
    "        scale = (i) / s\n",
    "        E[i, :] *= scale\n",
    "        E[-i-1, :] *= scale\n",
    "        E[:, i] *= scale\n",
    "        E[:, -i-1] *= scale\n",
    "\n",
    "    return E "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35765c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkerboard(height, width, block_size):\n",
    "    num_blocks_x = height // block_size \n",
    "    num_blocks_y = width // block_size\n",
    "    checker_pattern = (-1) ** (np.add.outer(np.arange(num_blocks_x), np.arange(num_blocks_y)))\n",
    "    result = np.kron(checker_pattern, np.ones((block_size, block_size)))\n",
    "    return result[:height, :width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88f418a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://gist.github.com/bmabey/4dd36d9938b83742a88b6f68ac1901a6\n",
    "def bwmorph_endpoints(image):\n",
    "    image = image.astype(np.int32)\n",
    "    k = np.array([[1,1,1],[1,0,1],[1,1,1]])\n",
    "    neighborhood_count = ndi.convolve(image,k, mode='constant', cval=1)\n",
    "    neighborhood_count[~image.astype(np.bool)] = 0\n",
    "    return neighborhood_count == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1f6aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(arr, y, x):\n",
    "    h, w = arr.shape\n",
    "    x1, x2 = max(x-1, 0), min(x+2, w)\n",
    "    y1, y2 = max(y-1, 0), min(y+2, h)\n",
    "    return arr[y1:y2, x1:x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e93e52b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixel_idx_list(labeled_image):\n",
    "    labels = np.unique(labeled_image)\n",
    "    labels = labels[labels != 0]  # Remove background if labeled as 0\n",
    "    return [np.flatnonzero(labeled_image == label) for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5d1b472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_cropper(image, cp, crop_wind):\n",
    "    y, x = cp\n",
    "    half = crop_wind // 2\n",
    "\n",
    "    y1, y2 = y - half, y + half + (crop_wind % 2)\n",
    "    x1, x2 = x - half, x + half + (crop_wind % 2)\n",
    "\n",
    "    # Handle edge cases by clipping indices to valid ranges\n",
    "    y1, y2 = max(0, y1), min(image.shape[0], y2)\n",
    "    x1, x2 = max(0, x1), min(image.shape[1], x2)\n",
    "\n",
    "    return image[y1:y2, x1:x2].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fc846eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_to_angle_deg(preds):\n",
    "    cos_vals, sin_vals = preds[:, 0], preds[:, 1]\n",
    "    angles_rad = torch.atan2(sin_vals, cos_vals)\n",
    "    angles_deg = torch.rad2deg(angles_rad)\n",
    "    return angles_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc76cfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_target_angles(p_step):\n",
    "    w_size = 2 * p_step + 1\n",
    "\n",
    "    # Create grid of coordinates relative to center\n",
    "    y, x = np.mgrid[-p_step:p_step+1, -p_step:p_step+1]\n",
    "\n",
    "    # Create mask with border set to 0\n",
    "    center_mask = np.ones((w_size, w_size), dtype=bool)\n",
    "    center_mask[0, :] = False\n",
    "    center_mask[-1, :] = False\n",
    "    center_mask[:, 0] = False\n",
    "    center_mask[:, -1] = False\n",
    "\n",
    "    # Compute angles, shift by pi, convert to degrees\n",
    "    vectormatrix = x + 1j * y\n",
    "    angle_deg = np.degrees(np.angle(vectormatrix) + np.pi)\n",
    "    angle_deg = np.round(angle_deg)\n",
    "\n",
    "    # Function to zero out specified angles in the inner region\n",
    "    def zero_angles(angles, center_mask, target_angles):\n",
    "        for t in target_angles:\n",
    "            angles[(angles == t) & center_mask] = 0\n",
    "        return angles\n",
    "\n",
    "    # Target angles to zero\n",
    "    targets = [0, 45, 90, 135, 180, 225, 270, 315, 360]\n",
    "\n",
    "    # Remove angles where inner mask is True\n",
    "    angle_deg = zero_angles(angle_deg, center_mask, targets)\n",
    "    angle_deg_mirr = np.flipud(angle_deg) * -1\n",
    "\n",
    "    # Get unique angles\n",
    "    unique_angles = np.unique(angle_deg).astype(np.int32)\n",
    "    unique_angles_mirr = np.unique(angle_deg_mirr).astype(np.int32)\n",
    "    return vectormatrix, angle_deg, angle_deg_mirr, unique_angles, unique_angles_mirr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67a36652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_values(img):\n",
    "    return (img - img.min()) / (img.max() - img.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06538c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Tracers [flipped=True]: 100%|██████████| 434/434 [00:07<00:00, 59.88it/s] \n",
      "Running Tracers [flipped=False]: 100%|██████████| 436/436 [00:06<00:00, 64.05it/s] \n"
     ]
    }
   ],
   "source": [
    "vectormatrix, angle_deg, angle_deg_mirr, unique_angles, unique_angles_mirr = compute_target_angles(p_step=3)\n",
    "\n",
    "files = zip(glob(\"data/input/rgb/*\"), glob(\"data/input/scm/*\"))\n",
    "data = [\n",
    "    [\n",
    "        cv2.imread(img_file)[...,::-1], \n",
    "        cv2.imread(cont_file, -1), \n",
    "        Path(img_file).stem\n",
    "    ]\n",
    "    for img_file, cont_file in files\n",
    "]\n",
    "\n",
    "# load model\n",
    "device = torch.accelerator.current_accelerator(True) if torch.accelerator.is_available() else \"cpu\"\n",
    "\n",
    "model = TracerNet()\n",
    "checkpoint = torch.load(\"data/models/best.pth\", weights_only=True, map_location=device)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for img, cont, filename in data:\n",
    "    img = img.astype(np.float32) * 256\n",
    "    cont = cont.astype(np.float32)\n",
    "\n",
    "    pad_width = [(50, 50), (50, 50)]\n",
    "    img = np.pad(img, pad_width + [(0, 0)], mode='constant', constant_values=0)\n",
    "    cont = np.pad(cont, pad_width, mode='constant', constant_values=0)\n",
    "    accumulator = np.zeros_like(cont)\n",
    "\n",
    "    for flipped in [True, False]:\n",
    "        img = np.flip(img, axis=1)\n",
    "        cont = np.flip(cont, axis=1)\n",
    "        accumulator = np.flip(accumulator, axis=1)\n",
    "\n",
    "        thresh = np.max(cont) * 0.5\n",
    "        cont_nms = nms(cont, r=3, s=2)\n",
    "        cont_nms[cont_nms < thresh] = 0\n",
    "        \n",
    "        cb_mask = checkerboard(*cont.shape, block_size=2)\n",
    "        if flipped: cont_nms[cb_mask > 0] = 0\n",
    "        else:       cont_nms[cb_mask < 0] = 0\n",
    "        cont_nms[cont_nms > 0] = 1\n",
    "\n",
    "        cont_nms = skeletonize(cont_nms.astype(bool))\n",
    "        cont_nms = remove_small_objects(cont_nms, min_size=2, connectivity=8)\n",
    "\n",
    "        labeled_image, segments = label(cont_nms, return_num=True)\n",
    "\n",
    "        endpoints = np.zeros((2, segments - 1, 2), dtype=np.int32)\n",
    "        endpoints_ang = np.zeros((2, segments - 1))\n",
    "        for i in range(0, segments - 1):\n",
    "            segment = labeled_image == i + 1\n",
    "            segment = ndi.binary_fill_holes(segment)\n",
    "            endpoints_mask = bwmorph_endpoints(segment)\n",
    "\n",
    "            coords = np.array(np.nonzero(endpoints_mask)).T\n",
    "            if len(coords) == 1: coords = np.repeat(coords, 2, axis=0)\n",
    "            if len(coords) != 2:\n",
    "                d = np.zeros(coords.size)\n",
    "                props = regionprops(segment.astype(np.int32))\n",
    "                x2, y2 = props[0].centroid\n",
    "                for j, (y1, x1) in enumerate(coords):\n",
    "                    d[j] = np.hypot(x2 - x1, y2 - y1)\n",
    "                endpoints[:, i] = coords[np.argsort(d)[-2:][::-1]]\n",
    "            else: endpoints[:, i] = coords\n",
    "\n",
    "            for ep_idx in range(2):\n",
    "                neighbors = get_neighbors(segment, *coords[ep_idx])\n",
    "                neighbors[1, 1] = 0\n",
    "                dy, dx = np.unravel_index(np.argmax(neighbors), neighbors.shape)\n",
    "                angle_rad = np.atan2(dy - 1, dx - 1)\n",
    "                endpoints_ang[ep_idx, i] = np.degrees(angle_rad) % 360\n",
    "\n",
    "        center_points = endpoints.reshape(-1, 2)\n",
    "        Y, X = center_points.T\n",
    "        prio = cont[Y, X]\n",
    "        angles = endpoints_ang.flatten()\n",
    "        group = labeled_image[Y, X]\n",
    "        running = np.ones(Y.shape, dtype=np.int32)\n",
    "        pix_list = get_pixel_idx_list(labeled_image)\n",
    "\n",
    "        interp_unique = interp1d(unique_angles, unique_angles, kind=\"nearest\", bounds_error=False)\n",
    "        interp_unique_mirr = interp1d(unique_angles_mirr, unique_angles_mirr, kind=\"nearest\", bounds_error=False)\n",
    "\n",
    "        inputs = np.concatenate([img, cont[...,None]], axis=2).astype(np.float32)\n",
    "        crop_size = 13\n",
    "\n",
    "        num_tracers = running.sum()\n",
    "        with tqdm(total=num_tracers, desc=f\"Running Tracers [flipped={flipped}]\") as pbar:\n",
    "            while num_tracers > 0:\n",
    "\n",
    "                mask = running == 1\n",
    "                X = X[mask]\n",
    "                Y = Y[mask]\n",
    "                prio = prio[mask]\n",
    "                angles = angles[mask]\n",
    "                group = group[mask]\n",
    "                running = running[mask]\n",
    "\n",
    "                center_points = np.column_stack([Y, X])\n",
    "\n",
    "                crops = []\n",
    "                for y, x, angle in zip(Y, X, angles):\n",
    "                    crop = tensor_cropper(inputs, [y, x], crop_size * 2 + 1)\n",
    "                    rot_crop = ndi.rotate(crop, angle, reshape=False, order=1)\n",
    "                    final_crop = tensor_cropper(rot_crop, [crop_size+1, crop_size+1], crop_size)\n",
    "                    crops.append(final_crop)\n",
    "                with torch.no_grad():\n",
    "                    tracer_input = torch.tensor(np.array(crops).transpose(0, 3, 2, 1)).to(device)\n",
    "                    preds = model(tracer_input)\n",
    "                    delta_angles = vector_to_angle_deg(preds).cpu().numpy()\n",
    "                angles = (angles + delta_angles) % 360\n",
    "\n",
    "                results = np.where(\n",
    "                    angles >= 0,\n",
    "                    interp_unique(angles),\n",
    "                    interp_unique_mirr(angles)\n",
    "                )\n",
    "\n",
    "                complex_dir = np.array([\n",
    "                    vectormatrix[angle_deg == res][0] if res > 0 else vectormatrix[angle_deg_mirr == res][0]\n",
    "                    for res in results\n",
    "                ])\n",
    "                magnitudes = np.abs(complex_dir)\n",
    "                step_size = np.abs(np.random.randn(num_tracers, 1))\n",
    "                step_size[step_size < 1] = 1\n",
    "                step_size[step_size >= 2.5] = 3\n",
    "\n",
    "                dir = np.column_stack((np.imag(complex_dir), np.real(complex_dir))) / magnitudes[:, None]\n",
    "                dir = np.round(dir * step_size)\n",
    "                angles = np.degrees(np.atan2(*-dir.T))\n",
    "\n",
    "                new_center_points = (center_points + dir).astype(np.int32)\n",
    "                Y, X = new_center_points.T\n",
    "                labeled_image[Y, X] = group\n",
    "                accumulator[Y, X] += 0.05\n",
    "\n",
    "                for i, (y, x, g) in enumerate(zip(Y, X, group)):\n",
    "                    g = int(g)\n",
    "                    prio[i] = cont[y, x]\n",
    "                    i_hel = np.ravel_multi_index([y, x], dims=segment.shape)\n",
    "                    if i_hel in pix_list[g] or prio[i] <= 15000:\n",
    "                        running[i] = 0\n",
    "                    else:\n",
    "                        pix_list[g] = np.append(pix_list[g], i_hel)\n",
    "\n",
    "                old_num_tracers = num_tracers\n",
    "                num_tracers = running.sum()\n",
    "                pbar.update(old_num_tracers - num_tracers)\n",
    "                # colored_labels = label2rgb(labeled_image, bg_label=0, kind='overlay')\n",
    "                # plt.clf()\n",
    "                # plt.title(f\"tracer: {num_tracers}\")\n",
    "                # plt.imshow(colored_labels)\n",
    "                # #plt.imshow(accumulator, cmap='gray')\n",
    "                # display.clear_output(wait=True)\n",
    "                # display.display(plt.gcf())\n",
    "    cv2.imwrite(f\"data/output/tracer_walk/{filename}.png\", (np.clip(accumulator, 0, 1) * 255).astype(np.uint8))\n",
    "    # cv2.imwrite(f\"data/output/tracer_walk/{filename}.png\", (rescale_values(accumulator) * 255).astype(np.uint8))\n",
    "plt.close(\"all\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wtl2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
